# Week 2: Regression with multiple input variables

This week, you'll extend linear regression to handle multiple input features. You'll also learn some methods for improving your model's training and performance, such as vectorization, feature scaling, feature engineering and polynomial regression. At the end of the week, you'll get to practice implementing linear regression in code.

# Videos
  - [x] Multiple features [link](https://www.coursera.org/learn/machine-learning/lecture/gFuSx/multiple-features)
  - [x] Vectorization part 1 [link](https://www.coursera.org/learn/machine-learning/lecture/ismjc/vectorization-part-1)
  - [x] Vectorization part 2 [link](https://www.coursera.org/learn/machine-learning/lecture/p2Nqv/vectorization-part-2)
  - [x] Gradient descent for multiple linear regression [link](https://www.coursera.org/learn/machine-learning/lecture/ltMMp/gradient-descent-for-multiple-linear-regression)
  - [x] Feature scaling part 1 [link](https://www.coursera.org/learn/machine-learning/lecture/KMDV3/feature-scaling-part-1)
  - [x] Feature scaling part 2 [link](https://www.coursera.org/learn/machine-learning/lecture/akapu/feature-scaling-part-2)
  - [x] Checking gradient descent for convergence [link](https://www.coursera.org/learn/machine-learning/lecture/rOTkB/checking-gradient-descent-for-convergence)
  - [x] Choosing the learning rate [link](https://www.coursera.org/learn/machine-learning/lecture/10ZVv/choosing-the-learning-rate)
  - [x] Feature engineering [link](https://www.coursera.org/learn/machine-learning/lecture/dgZYR/feature-engineering)
  - [x] Polynomial regression [link](https://www.coursera.org/learn/machine-learning/lecture/OnGhN/polynomial-regression)